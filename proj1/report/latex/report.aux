\relax 
\providecommand\zref@newlabel[2]{}
\citation{kubat}
\citation{scikit}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Task}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Introduction}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Method}{1}}
\citation{iris}
\@writefile{toc}{\contentsline {section}{\numberline {4}Iris Dataset}{2}}
\citation{wine}
\bibstyle{plainurl}
\bibdata{bibi}
\@writefile{toc}{\contentsline {section}{\numberline {5}Animal Dataset}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Wine Dataset}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusion}{3}}
\bibcite{iris}{1}
\bibcite{wine}{2}
\bibcite{kubat}{3}
\bibcite{scikit}{4}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces These two graphs show the performance of our classifier against the Scikit \textit  {k}-NN classifier. They behave identically for \textit  {k} = 1 but begin to vary at k-values higher than one.}}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces This shows our classifier with all values of \textit  {k} we tested on the Iris dataset. For all classifiers, the steepest drop in accuracy is with the introduction of the first 6 irrelevant attributes, after which our classifier converges at around 30\% accuracy.}}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Irrelevant attributes again are shown to decrease the accuracy rate for all values of \textit  {k} in our classifier. Here, the descent is a bit more gradual, but once more the accuracy ends up at around 30\%.}}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The first color map shows where an example would have to land in the Iris dataset to be classified as one of the three classes. This map uses two relevant attributes on the axes. The latter two color maps show that as the ranges of irrelevant attributes increase, the classification suffers as there is no correlation between an example's classification and the example's irrelevant attribute value.}}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces This graph compares the performance of our 1-NN classifier on both datasets. It demonstrates how the irrelevant attributes cause a sharper decline in the Iris dataset and how they decrease the classifierâ€™s accuracy on both datasets.}}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces This graph shows our 3-NN on the Wine dataset. It demonstrates that the lower accuracy demonstrated in all other graphs is not merely a result of additional attributes, but of specifically irrelevant attributes. Here we add relevant attributes two at a time and the accuracy is improved.}}{7}}
